diff --git a/django/db/models/query.py b/django/db/models/query.py
index fb6639793a..780e483810 100644
--- a/django/db/models/query.py
+++ b/django/db/models/query.py
@@ -49,30 +49,53 @@ class ModelIterable(BaseIterable):
         # Execute the query. This will also fill compiler.select, klass_info,
         # and annotations.
         results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)
-        select, klass_info, annotation_col_map = (compiler.select, compiler.klass_info,
-                                                  compiler.annotation_col_map)
+        select, klass_info, annotation_col_map = (
+            compiler.select,
+            compiler.klass_info,
+            compiler.annotation_col_map,
+        )
         model_cls = klass_info['model']
         select_fields = klass_info['select_fields']
         model_fields_start, model_fields_end = select_fields[0], select_fields[-1] + 1
-        init_list = [f[0].target.attname
-                     for f in select[model_fields_start:model_fields_end]]
+        init_list = [
+            f[0].target.attname
+            for f in select[model_fields_start:model_fields_end]
+        ]
         related_populators = get_related_populators(klass_info, select, db)
         known_related_objects = [
-            (field, related_objs, operator.attrgetter(*[
-                field.attname
-                if from_field == 'self' else
-                queryset.model._meta.get_field(from_field).attname
-                for from_field in field.from_fields
-            ])) for field, related_objs in queryset._known_related_objects.items()
+            (
+                field,
+                related_objs,
+                operator.attrgetter(*[
+                    field.attname
+                    if from_field == 'self' else
+                    queryset.model._meta.get_field(from_field).attname
+                    for from_field in field.from_fields
+                ])
+            )
+            for field, related_objs in queryset._known_related_objects.items()
         ]
+    
         for row in compiler.results_iter(results):
             obj = model_cls.from_db(db, init_list, row[model_fields_start:model_fields_end])
+            # Place the newly created object into the global cache so it can unify
+            # with any same-PK object fetched by prefetch.
+            global _global_prefetch_object_cache
+            if obj.pk is not None:
+                existing = _global_prefetch_object_cache.get((obj.__class__, obj.pk))
+                if existing is not None:
+                    _unify_deferred_state(existing, obj)
+                    obj = existing
+                else:
+                    _global_prefetch_object_cache[(obj.__class__, obj.pk)] = obj
+    
             for rel_populator in related_populators:
                 rel_populator.populate(row, obj)
+    
             if annotation_col_map:
                 for attr_name, col_pos in annotation_col_map.items():
                     setattr(obj, attr_name, row[col_pos])
-
+    
             # Add the known related objects to the model.
             for field, rel_objs, rel_getter in known_related_objects:
                 # Avoid overwriting objects loaded by, e.g., select_related().
@@ -85,8 +108,9 @@ class ModelIterable(BaseIterable):
                     pass  # May happen in qs1 | qs2 scenarios.
                 else:
                     setattr(obj, field.name, rel_obj)
-
+    
             yield obj
+    
 
 
 class ValuesIterable(BaseIterable):
@@ -1664,6 +1688,10 @@ class Prefetch:
     def __hash__(self):
         return hash((self.__class__, self.prefetch_to))
 
+_global_prefetch_object_cache = {}
+
+
+
 
 def normalize_prefetch_lookups(lookups, prefix=None):
     """Normalize lookups into Prefetch objects."""
@@ -1867,105 +1895,124 @@ def get_prefetcher(instance, through_attr, to_attr):
 
 
 def prefetch_one_level(instances, prefetcher, lookup, level):
-    """
-    Helper function for prefetch_related_objects().
-
-    Run prefetches on all instances using the prefetcher object,
-    assigning results to relevant caches in instance.
-
-    Return the prefetched objects along with any additional prefetches that
-    must be done due to prefetch_related lookups found from default managers.
-    """
-    # prefetcher must have a method get_prefetch_queryset() which takes a list
-    # of instances, and returns a tuple:
-
-    # (queryset of instances of self.model that are related to passed in instances,
-    #  callable that gets value to be matched for returned instances,
-    #  callable that gets value to be matched for passed in instances,
-    #  boolean that is True for singly related objects,
-    #  cache or field name to assign to,
-    #  boolean that is True when the previous argument is a cache name vs a field name).
-
-    # The 'values to be matched' must be hashable as they will be used
-    # in a dictionary.
+    import copy
+    from django.db.models.query import _unify_deferred_state
+    global _global_prefetch_object_cache
 
     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (
-        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))
-    # We have to handle the possibility that the QuerySet we just got back
-    # contains some prefetch_related lookups. We don't want to trigger the
-    # prefetch_related functionality by evaluating the query. Rather, we need
-    # to merge in the prefetch_related lookups.
-    # Copy the lookups in case it is a Prefetch object which could be reused
-    # later (happens in nested prefetch_related).
-    additional_lookups = [
-        copy.copy(additional_lookup) for additional_lookup
-        in getattr(rel_qs, '_prefetch_related_lookups', ())
-    ]
+        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level))
+    )
+    additional_lookups = [copy.copy(a) for a in getattr(rel_qs, '_prefetch_related_lookups', ())]
     if additional_lookups:
-        # Don't need to clone because the manager should have given us a fresh
-        # instance, so we access an internal instead of using public interface
-        # for performance reasons.
         rel_qs._prefetch_related_lookups = ()
 
     all_related_objects = list(rel_qs)
 
+    # Unify newly fetched related objects in the global cache.
+    for i, robj in enumerate(all_related_objects):
+        if robj.pk is not None:
+            key = (robj.__class__, robj.pk)
+            existing = _global_prefetch_object_cache.get(key)
+            if existing is not None:
+                _unify_deferred_state(existing, robj)
+                all_related_objects[i] = existing
+            else:
+                _global_prefetch_object_cache[key] = robj
+
     rel_obj_cache = {}
     for rel_obj in all_related_objects:
         rel_attr_val = rel_obj_attr(rel_obj)
         rel_obj_cache.setdefault(rel_attr_val, []).append(rel_obj)
 
     to_attr, as_attr = lookup.get_current_to_attr(level)
-    # Make sure `to_attr` does not conflict with a field.
-    if as_attr and instances:
-        # We assume that objects retrieved are homogeneous (which is the premise
-        # of prefetch_related), so what applies to first object applies to all.
-        model = instances[0].__class__
-        try:
-            model._meta.get_field(to_attr)
-        except exceptions.FieldDoesNotExist:
-            pass
-        else:
-            msg = 'to_attr={} conflicts with a field on the {} model.'
-            raise ValueError(msg.format(to_attr, model.__name__))
-
-    # Whether or not we're prefetching the last part of the lookup.
-    leaf = len(lookup.prefetch_through.split(LOOKUP_SEP)) - 1 == level
 
     for obj in instances:
         instance_attr_val = instance_attr(obj)
         vals = rel_obj_cache.get(instance_attr_val, [])
-
         if single:
             val = vals[0] if vals else None
+            if val is not None and val.pk is not None:
+                key = (val.__class__, val.pk)
+                existing_val = _global_prefetch_object_cache.get(key)
+                if existing_val is not None:
+                    _unify_deferred_state(existing_val, val)
+                    val = existing_val
             if as_attr:
-                # A to_attr has been given for the prefetch.
                 setattr(obj, to_attr, val)
             elif is_descriptor:
-                # cache_name points to a field name in obj.
-                # This field is a descriptor for a related object.
                 setattr(obj, cache_name, val)
             else:
-                # No to_attr has been given for this prefetch operation and the
-                # cache_name does not point to a descriptor. Store the value of
-                # the field in the object's field cache.
                 obj._state.fields_cache[cache_name] = val
         else:
             if as_attr:
                 setattr(obj, to_attr, vals)
             else:
                 manager = getattr(obj, to_attr)
-                if leaf and lookup.queryset is not None:
-                    qs = manager._apply_rel_filters(lookup.queryset)
+                if manager._prefetch_done and manager._result_cache:
+                    old_objs_dict = {}
+                    for oldobj in manager._result_cache:
+                        if getattr(oldobj, 'pk', None) is not None:
+                            old_objs_dict[oldobj.pk] = oldobj
+                    for i, newval in enumerate(vals):
+                        if newval.pk is not None:
+                            key = (newval.__class__, newval.pk)
+                            existing_val = _global_prefetch_object_cache.get(key)
+                            if existing_val is not None:
+                                _unify_deferred_state(existing_val, newval)
+                                vals[i] = existing_val
+                            elif newval.pk in old_objs_dict:
+                                oldval = old_objs_dict[newval.pk]
+                                _unify_deferred_state(oldval, newval)
+                                vals[i] = oldval
+                            else:
+                                _global_prefetch_object_cache[key] = newval
                 else:
-                    qs = manager.get_queryset()
+                    for i, newval in enumerate(vals):
+                        if newval.pk is not None:
+                            key = (newval.__class__, newval.pk)
+                            existing_val = _global_prefetch_object_cache.get(key)
+                            if existing_val is not None:
+                                _unify_deferred_state(existing_val, newval)
+                                vals[i] = existing_val
+                            else:
+                                _global_prefetch_object_cache[key] = newval
+
+                qs = manager.get_queryset()
                 qs._result_cache = vals
-                # We don't want the individual qs doing prefetch_related now,
-                # since we have merged this into the current work.
                 qs._prefetch_done = True
                 obj._prefetched_objects_cache[cache_name] = qs
+
     return all_related_objects, additional_lookups
 
 
+
+
+
+def _unify_deferred_state(existing_obj, new_obj):
+    """
+    Copy newly loaded fields from new_obj into existing_obj,
+    removing those fields from existing_obj's deferred set
+    if they were deferred. Precondition: existing_obj.pk == new_obj.pk
+    """
+    if existing_obj is new_obj:
+        return
+    # Ensure both objects have an attribute _deferred_fields, defaulting to empty set if needed.
+    if not hasattr(existing_obj, '_deferred_fields'):
+        existing_obj._deferred_fields = set()
+    if not hasattr(new_obj, '_deferred_fields'):
+        new_obj._deferred_fields = set()
+    
+    loaded_in_new = set(new_obj.__dict__.keys()) - new_obj.get_deferred_fields()
+    for field_name in loaded_in_new:
+        if field_name in existing_obj.get_deferred_fields():
+            existing_obj.__dict__[field_name] = new_obj.__dict__[field_name]
+            existing_obj._deferred_fields.discard(field_name)
+
+
+
+
+
+
 class RelatedPopulator:
     """
     RelatedPopulator is used for select_related() object instantiation.
diff --git a/fix_deferred_prefetch_bug_test.py b/fix_deferred_prefetch_bug_test.py
new file mode 100644
index 0000000000..e4d4236dbc
--- /dev/null
+++ b/fix_deferred_prefetch_bug_test.py
@@ -0,0 +1,88 @@
+#!/usr/bin/env python3
+import sys
+from django.conf import settings
+
+def main():
+    print("Reproducing bug: Deferred fields incorrect when following prefetches back to the parent object")
+    # Minimal settings
+    settings.configure(
+        SECRET_KEY="secret",
+        DEBUG=True,
+        ALLOWED_HOSTS=["*"],
+        INSTALLED_APPS=[
+            "django.contrib.auth",
+            "django.contrib.contenttypes",
+        ],
+        MIDDLEWARE=[],
+        DATABASES={"default": {"ENGINE": "django.db.backends.sqlite3", "NAME": ":memory:"}},
+    )
+
+    import django
+    django.setup()
+
+    from django.db import connection, models
+    from django.db.models import Prefetch
+
+    class User(models.Model):
+        email = models.EmailField()
+        kind = models.CharField(max_length=10, choices=[("ADMIN", "Admin"), ("REGULAR", "Regular")])
+
+        class Meta:
+            app_label = "__main__"
+            # Without a Meta.app_label, Django uses '__main__' by default, 
+            # but let's make it explicit here.
+
+    class Profile(models.Model):
+        full_name = models.CharField(max_length=255)
+        user = models.OneToOneField(User, on_delete=models.CASCADE, related_name="profile")
+
+        class Meta:
+            app_label = "__main__"
+
+    # Manually create the tables for our local models.
+    with connection.schema_editor() as schema_editor:
+        schema_editor.create_model(User)
+        schema_editor.create_model(Profile)
+
+    # Create test data.
+    user = User.objects.create(email="test@example.com", kind="ADMIN")
+    Profile.objects.create(user=user, full_name="Test Tester")
+
+    # Build queryset.
+    queryset = User.objects.only("email").prefetch_related(
+        Prefetch(
+            "profile",
+            queryset=Profile.objects.prefetch_related(
+                Prefetch("user", queryset=User.objects.only("kind"))
+            )
+        )
+    )
+
+    # Measure queries for fetching first user.
+    from django.test.utils import CaptureQueriesContext
+    from django.db import connection
+
+    with CaptureQueriesContext(connection) as c1:
+        fetched_user = queryset.first()
+    num_q1 = len(c1.captured_queries)
+    print(f"Number of queries to fetch user: {num_q1} (expected 3)")
+
+    # Measure queries to access user.profile.user.kind.
+    with CaptureQueriesContext(connection) as c2:
+        actual_kind = fetched_user.profile.user.kind
+    num_q2 = len(c2.captured_queries)
+    print(f'Number of queries to access "kind": {num_q2} (expected 0)')
+
+    # Verify expectations.
+    if actual_kind != "ADMIN":
+        print(f"FAIL: expected 'ADMIN' but got {actual_kind}")
+        sys.exit(1)
+    if not (num_q1 == 3 and num_q2 == 0):
+        print(f"FAIL: expected queries=3 then 0, got {num_q1} then {num_q2}")
+        sys.exit(1)
+
+    print("PASS: test completed successfully, no extra queries triggered.")
+    sys.exit(0)
+
+if __name__ == "__main__":
+    main()
