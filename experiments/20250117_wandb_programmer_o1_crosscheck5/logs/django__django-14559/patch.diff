diff --git a/check_bulk_update_return_value.py b/check_bulk_update_return_value.py
new file mode 100644
index 0000000000..f2cd608608
--- /dev/null
+++ b/check_bulk_update_return_value.py
@@ -0,0 +1,62 @@
+import sys
+import django
+from django.conf import settings
+from django.db import models, connection
+from django.core.management import call_command
+
+DB_NAME = ":memory:"
+
+# Minimal Django settings for an in-memory sqlite database.
+settings.configure(
+    INSTALLED_APPS=[],
+    DATABASES={
+        "default": {
+            "ENGINE": "django.db.backends.sqlite3",
+            "NAME": DB_NAME,
+        }
+    },
+    SECRET_KEY="testsecretkey",
+)
+
+def main():
+    print("Starting test for bulk_update return value.")
+    django.setup()
+
+    class BulkUpdateTestModel(models.Model):
+        name = models.CharField(max_length=50)
+        value = models.IntegerField()
+
+        class Meta:
+            app_label = "bulk_update_test_app"  # Just a placeholder; no real migrations.
+
+    # Manually create the table for BulkUpdateTestModel.
+    with connection.schema_editor() as schema_editor:
+        schema_editor.create_model(BulkUpdateTestModel)
+
+    print("Creating objects...")
+    objs = [
+        BulkUpdateTestModel.objects.create(name="obj1", value=1),
+        BulkUpdateTestModel.objects.create(name="obj2", value=2),
+        BulkUpdateTestModel.objects.create(name="obj3", value=3),
+    ]
+
+    for obj in objs:
+        obj.value += 10
+
+    print("Calling bulk_update() on these objects...")
+    rows_updated = BulkUpdateTestModel.objects.bulk_update(objs, ["value"])
+    print(f"bulk_update() returned: {rows_updated!r}")
+
+    # Expect an integer equal to the number of updated rows.
+    if not isinstance(rows_updated, int):
+        print("FAIL: bulk_update() did not return an integer.")
+        sys.exit(1)
+    if rows_updated != len(objs):
+        print(f"FAIL: Expected {len(objs)} but got {rows_updated}")
+        sys.exit(1)
+
+    print("PASS: bulk_update() returned an integer matching the number of rows updated.")
+    sys.exit(0)
+
+if __name__ == "__main__":
+    main()
diff --git a/django/db/models/query.py b/django/db/models/query.py
index 387deca527..792e74db7f 100644
--- a/django/db/models/query.py
+++ b/django/db/models/query.py
@@ -541,9 +541,7 @@ class QuerySet:
         if any(f.primary_key for f in fields):
             raise ValueError('bulk_update() cannot be used with primary key fields.')
         if not objs:
-            return
-        # PK is used twice in the resulting update query, once in the filter
-        # and once in the WHEN. Each field will also have one CAST.
+            return 0
         max_batch_size = connections[self.db].ops.bulk_batch_size(['pk', 'pk'] + fields, objs)
         batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size
         requires_casting = connections[self.db].features.requires_casted_case_in_updates
@@ -563,9 +561,13 @@ class QuerySet:
                     case_statement = Cast(case_statement, output_field=field)
                 update_kwargs[field.attname] = case_statement
             updates.append(([obj.pk for obj in batch_objs], update_kwargs))
+        total_updated = 0
         with transaction.atomic(using=self.db, savepoint=False):
             for pks, update_kwargs in updates:
-                self.filter(pk__in=pks).update(**update_kwargs)
+                updated_count = self.filter(pk__in=pks).update(**update_kwargs)
+                total_updated += updated_count
+        return total_updated
+    
     bulk_update.alters_data = True
 
     def get_or_create(self, defaults=None, **kwargs):
