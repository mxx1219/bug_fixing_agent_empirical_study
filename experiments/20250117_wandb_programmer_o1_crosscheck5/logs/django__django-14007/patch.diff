diff --git a/django/db/models/base.py b/django/db/models/base.py
index 55b1691166..5aa0eb6026 100644
--- a/django/db/models/base.py
+++ b/django/db/models/base.py
@@ -818,11 +818,11 @@ class Model(metaclass=ModelBase):
         """
         meta = cls._meta
         non_pks = [f for f in meta.local_concrete_fields if not f.primary_key]
-
+    
         if update_fields:
             non_pks = [f for f in non_pks
                        if f.name in update_fields or f.attname in update_fields]
-
+    
         pk_val = self._get_pk_val(meta)
         if pk_val is None:
             pk_val = meta.pk.get_pk_value_on_save(self)
@@ -843,11 +843,12 @@ class Model(metaclass=ModelBase):
         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.
         if pk_set and not force_insert:
             base_qs = cls._base_manager.using(using)
-            values = [(f, None, (getattr(self, f.attname) if raw else f.pre_save(self, False)))
-                      for f in non_pks]
+            values = [
+                (f, None, (getattr(self, f.attname) if raw else f.pre_save(self, False)))
+                for f in non_pks
+            ]
             forced_update = update_fields or force_update
-            updated = self._do_update(base_qs, using, pk_val, values, update_fields,
-                                      forced_update)
+            updated = self._do_update(base_qs, using, pk_val, values, update_fields, forced_update)
             if force_update and not updated:
                 raise DatabaseError("Forced update did not affect any rows.")
             if update_fields and not updated:
@@ -867,13 +868,18 @@ class Model(metaclass=ModelBase):
             fields = meta.local_concrete_fields
             if not pk_set:
                 fields = [f for f in fields if f is not meta.auto_field]
-
+    
             returning_fields = meta.db_returning_fields
             results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
             if results:
+                from django.db import connections
+                conn = connections[using]
                 for value, field in zip(results[0], returning_fields):
+                    if hasattr(field, 'from_db_value') and value is not None:
+                        value = field.from_db_value(value, None, conn)
                     setattr(self, field.attname, value)
         return updated
+    
 
     def _do_update(self, base_qs, using, pk_val, values, update_fields, forced_update):
         """
diff --git a/django/db/models/query.py b/django/db/models/query.py
index 387deca527..d288b3576f 100644
--- a/django/db/models/query.py
+++ b/django/db/models/query.py
@@ -468,29 +468,14 @@ class QuerySet:
         autoincrement field (except if features.can_return_rows_from_bulk_insert=True).
         Multi-table models are not supported.
         """
-        # When you bulk insert you don't get the primary keys back (if it's an
-        # autoincrement, except if can_return_rows_from_bulk_insert=True), so
-        # you can't insert into the child tables which references this. There
-        # are two workarounds:
-        # 1) This could be implemented if you didn't have an autoincrement pk
-        # 2) You could do it by doing O(n) normal inserts into the parent
-        #    tables to get the primary keys back and then doing a single bulk
-        #    insert into the childmost table.
-        # We currently set the primary keys on the objects when using
-        # PostgreSQL via the RETURNING ID clause. It should be possible for
-        # Oracle as well, but the semantics for extracting the primary keys is
-        # trickier so it's not done yet.
         assert batch_size is None or batch_size > 0
-        # Check that the parents share the same concrete model with the our
-        # model to detect the inheritance pattern ConcreteGrandParent ->
-        # MultiTableParent -> ProxyChild. Simply checking self.model._meta.proxy
-        # would not identify that case as involving multiple tables.
         for parent in self.model._meta.get_parent_list():
             if parent._meta.concrete_model is not self.model._meta.concrete_model:
                 raise ValueError("Can't bulk create a multi-table inherited model")
         if not objs:
             return objs
         self._for_write = True
+        from django.db import connections
         connection = connections[self.db]
         opts = self.model._meta
         fields = opts.concrete_fields
@@ -502,10 +487,11 @@ class QuerySet:
                 returned_columns = self._batched_insert(
                     objs_with_pk, fields, batch_size, ignore_conflicts=ignore_conflicts,
                 )
-                for obj_with_pk, results in zip(objs_with_pk, returned_columns):
-                    for result, field in zip(results, opts.db_returning_fields):
-                        if field != opts.pk:
-                            setattr(obj_with_pk, field.attname, result)
+                for obj_with_pk, results_ in zip(objs_with_pk, returned_columns):
+                    for value, field in zip(results_, opts.db_returning_fields):
+                        if hasattr(field, 'from_db_value') and value is not None:
+                            value = field.from_db_value(value, None, connection)
+                        setattr(obj_with_pk, field.attname, value)
                 for obj_with_pk in objs_with_pk:
                     obj_with_pk._state.adding = False
                     obj_with_pk._state.db = self.db
@@ -516,13 +502,15 @@ class QuerySet:
                 )
                 if connection.features.can_return_rows_from_bulk_insert and not ignore_conflicts:
                     assert len(returned_columns) == len(objs_without_pk)
-                for obj_without_pk, results in zip(objs_without_pk, returned_columns):
-                    for result, field in zip(results, opts.db_returning_fields):
-                        setattr(obj_without_pk, field.attname, result)
+                for obj_without_pk, results_ in zip(objs_without_pk, returned_columns):
+                    for value, field in zip(results_, opts.db_returning_fields):
+                        if hasattr(field, 'from_db_value') and value is not None:
+                            value = field.from_db_value(value, None, connection)
+                        setattr(obj_without_pk, field.attname, value)
                     obj_without_pk._state.adding = False
                     obj_without_pk._state.db = self.db
-
         return objs
+    
 
     def bulk_update(self, objs, fields, batch_size=None):
         """
diff --git a/test_from_db_value_on_insert.py b/test_from_db_value_on_insert.py
new file mode 100644
index 0000000000..b39bfe2b5a
--- /dev/null
+++ b/test_from_db_value_on_insert.py
@@ -0,0 +1,77 @@
+import sys
+import django
+from django.conf import settings
+from django.db import models, connection
+from django.db.models import AutoField
+
+# Minimal Django settings:
+if not settings.configured:
+    settings.configure(
+        INSTALLED_APPS=["__main__"],
+        DATABASES={
+            "default": {
+                "ENGINE": "django.db.backends.sqlite3",
+                "NAME": ":memory:",
+            }
+        },
+        MIDDLEWARE=[],
+    )
+
+django.setup()
+
+class MyIntWrapper(int):
+    pass
+
+class MyAutoField(models.BigAutoField):
+    def from_db_value(self, value, expression, conn):
+        if value is None:
+            return None
+        return MyIntWrapper(value)
+
+    def get_prep_value(self, value):
+        if value is None:
+            return None
+        return int(value)
+
+class AutoModel(models.Model):
+    id = MyAutoField(primary_key=True)
+
+    class Meta:
+        db_table = "test_automodel_table"
+        app_label = "__main__"
+        managed = True
+
+def main():
+    print("Creating table for AutoModel...")
+    with connection.schema_editor() as editor:
+        editor.create_model(AutoModel)
+
+    print("Running from_db_value test on inserts...")
+
+    # Test normal create()
+    obj = AutoModel.objects.create()
+    print(f"Created object with id = {obj.id} (type={type(obj.id)})")
+    if not isinstance(obj.id, MyIntWrapper):
+        print("FAIL: from_db_value was NOT called on normal create()")
+        sys.exit(1)
+
+    # If the DB doesnâ€™t support returning columns from bulk inserts, skip that test.
+    if not connection.features.can_return_rows_from_bulk_insert:
+        print("SKIP: Database doesn't support returning columns from bulk INSERT. Cannot test bulk_create PK.")
+        print("PASS: from_db_value was called on create() for unsupported bulk_create DB.")
+        sys.exit(0)
+
+    # Test objects.bulk_create() if returning is supported.
+    objs = [AutoModel()]
+    AutoModel.objects.bulk_create(objs)
+    created_obj = objs[0]
+    print(f"Bulk-created object with id = {created_obj.id} (type={type(created_obj.id)})")
+    if not isinstance(created_obj.id, MyIntWrapper):
+        print("FAIL: from_db_value was NOT called on bulk_create (though DB supports return).")
+        sys.exit(2)
+
+    print("PASS: from_db_value was called for both normal create() and bulk_create().")
+    sys.exit(0)
+
+if __name__ == "__main__":
+    main()
