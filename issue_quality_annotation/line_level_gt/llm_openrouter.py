import os
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time
import json
import multiprocessing

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

def send_request(model, messages, temperature = 0.0, n = 1):
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}"
    }
    data = {
        "model": model,
        "messages": messages,
        "top_p": 1,
        "n": n,
        "temperature": temperature,
        "max_tokens": 1024*8,
    }
    data["messages"] = messages
    length = sum(len(str(obj)) for obj in messages)

    session = requests.Session()

    retry_limit = 3
    current_retry = 0
    while True:
        retry = Retry(
            total=15, 
            backoff_factor=2,  
            status_forcelist=tuple(range(401, 6000)),  
            allowed_methods=["POST"] 
        )
        adapter = HTTPAdapter(max_retries=retry)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        chat_url = "https://openrouter.ai/api/v1/chat/completions"

        response = session.post(chat_url, json=data, headers=headers, timeout=(120, 300))

        parse_error = False
        resp_json = {}
        try:
            resp_json = response.json()
            _ = resp_json["choices"][0]
        except:
            parse_error = True

        if parse_error or response.status_code != 200 or "error" in resp_json["choices"][0]:
            print("response.status_code: ", response.status_code)
            # print(response.text)
            if length > 200000:
                raise Exception(f"Token limit protect! Message length: {length}")
            time.sleep(30) # Prevent tpm from being maxed out
            current_retry += 1
            if current_retry >= retry_limit:
                break
            else:
                continue
            
        return resp_json

    raise Exception(f"Failed to get response from LLM, Message length: {length}")


def get_llm_response(model: str, messages, temperature = 0.0, n = 1):
    decoded_answer = []
    assistant_response = send_request(model, messages, temperature, n)
    
    for choice in assistant_response["choices"]:
        decoded_answer.append(choice["message"]["content"])
    # print(assistant_response["usage"])
    return decoded_answer[0], assistant_response["usage"]


def predict(item):
    instance_id = item["instance_id"]
    problem_statment = item["problem_statement"]
    patch_content = item["patch_content"]
    print(instance_id)
    messages = [
        {
            "role": "system",
            "content":
f"""
You are a data annotator. Specifically, you need to complete the following task:
A user encountered a problem while using an open-source project and subsequently raised an issue. The developer saw the issue and provided a solution (the solution was given by editing the code and submitting a patch). We will provide you with the complete description of the issue reported by the user, as well as the detailed description of the patch generated by the developer to address the problem. Compared to the standard diff format of patches, the patch we provide to you displays the old and new line numbers of the edited code lines (in the main body of the patch, the first number at the beginning of the line represents the old line number, the second number represents the new line number; you need to pay attention to the old line number). We believe this will better help you complete the following tasks. You need to carefully review the issue description and the patch information, and annotate whether the modified code lines appear in the issue description text and in what form they are given. For the "form given," you need to choose one of the following options:
(1) Option: StackTrace. Explanation: The issue description text includes a StackTrace related to the problem, and the file name and line number information of the edited code must directly appear in the StackTrace!
(2) Option: Keyword. Explanation: The issue description text directly includes code line information, and the file name and line number information of the edited code must directly appear in it (must correspond to the modified numbers in the patch, not adjacent line numbers).
(3) Natural Language. Explanation: The issue description text contains complete or partial code line information described in natural language. Compared to (2), it does not directly include the unique line number identifier. For example, if the patch contains a modified code line "result = get_content(url proxy, timeout)," you can this option if the description includes content likeresult =_content(url, proxy, timeout)" or "get_content(url, proxy, timeout)." If it only includes some identifiers that cannot directly help locate that line, such as "proxy" or "timeout," this option should not be chosen.
(4) Option: No Information. Explanation: When you believe that it is impossible to directly locate any modified code line in the patch based on the issue description content, please choose this option. You do not need to make extra efforts based on your knowledge; we only need you to make an objective assessment based on the literal content. If there is no information, there is no information.

Please note that the aforementioned options (1) to (4) represent a decreasing level of relevance. If multiple options are simultaneously satisfied, you can only respond with the highest level option (for example, if StackTrace, Keyword, and Natural Language are all satisfied, your annotation result should be StackTrace). Additionally, please note that a patch may contain more than one modified code line; the current annotation task is about the existence of information, meaning if any modified code line meets the above options, you should choose the corresponding option!

Your final report must be written in the following form:
```
## Annotation Level: xxx (choose one of the four)
## Supporting Reason: xxx (as concise as possible)
```
"""
        },     
        {
            "role": "user",
            "content":                 
f"""
The issue description is as follows:
```
{problem_statment}
```

The patch content to resolve this issue is as follows:
```
{patch_content}
```
Please return the annotated report to me as required after careful reading and analysis.
"""
        }
    ]
    response, usage = get_llm_response("deepseek/deepseek-r1", messages)
    os.makedirs("./predict_dsr1/")
    with open(f"./predict_dsr1/{instance_id}.txt", "w") as file:
        file.write(response)


def worker(task_queue):
    while True:
        task = task_queue.get()
        if task is None:
            break
        item = task
        predict(item)


def main():
    num_processes = 1
    
    with open("../../swe_bench_verified.json", "r") as file:
        items = json.load(file)
    
    patch_info = {}
    for patch_name in os.listdir("./delta_diff/"):
        with open(os.path.join("./delta_diff/", patch_name), "r") as file:
            patch_info[patch_name[:-6]] = file.read().strip().replace("\u22ee", "|").replace("\u2502", "|")
    task_queue = multiprocessing.Queue()
    
    pool = []
    for _ in range(num_processes):
        p = multiprocessing.Process(target=worker, args=(task_queue,))
        p.start()
        pool.append(p)

    tasks = []
    for item in items:
        item["patch_content"] = patch_info[item["instance_id"]]
        tasks.append(item)
    print(len(tasks))

    for task in tasks:
        task_queue.put(task)
    
    for _ in range(num_processes):
        task_queue.put(None)

    for p in pool:
        p.join()


if __name__ == "__main__":
    main()