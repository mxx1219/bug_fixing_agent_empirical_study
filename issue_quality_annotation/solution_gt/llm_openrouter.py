import os
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time
import json
import multiprocessing

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

def send_request(model, messages, temperature = 0.0, n = 1):
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}"
    }
    data = {
        "model": model,
        "messages": messages,
        "top_p": 1,
        "n": n,
        "temperature": temperature,
        "max_tokens": 1024*8,
    }
    data["messages"] = messages
    length = sum(len(str(obj)) for obj in messages)

    session = requests.Session()

    retry_limit = 3
    current_retry = 0
    while True:
        retry = Retry(
            total=15, 
            backoff_factor=2,  
            status_forcelist=tuple(range(401, 6000)),  
            allowed_methods=["POST"] 
        )
        adapter = HTTPAdapter(max_retries=retry)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        chat_url = "https://openrouter.ai/api/v1/chat/completions"

        response = session.post(chat_url, json=data, headers=headers, timeout=(120, 300))

        parse_error = False
        resp_json = {}
        try:
            resp_json = response.json()
            _ = resp_json["choices"][0]
        except:
            parse_error = True

        if parse_error or response.status_code != 200 or "error" in resp_json["choices"][0]:
            print("response.status_code: ", response.status_code)
            # print(response.text)
            if length > 200000:
                raise Exception(f"Token limit protect! Message length: {length}")
            time.sleep(30) # Prevent tpm from being maxed out
            current_retry += 1
            if current_retry >= retry_limit:
                break
            else:
                continue
            
        return resp_json

    raise Exception(f"Failed to get response from LLM, Message length: {length}")


def get_llm_response(model: str, messages, temperature = 0.0, n = 1):
    decoded_answer = []
    assistant_response = send_request(model, messages, temperature, n)
    
    for choice in assistant_response["choices"]:
        decoded_answer.append(choice["message"]["content"])
    # print(assistant_response["usage"])
    return decoded_answer[0], assistant_response["usage"]


def predict(item):
    instance_id = item["instance_id"]
    problem_statment = item["problem_statement"]
    patch_content = item["patch_content"]
    print(instance_id)
    messages = [
        {
            "role": "system",
            "content":
f"""
You are a data annotator. Specifically, you need to complete the following tasks:
While using an open-source project, a user encountered a problem and subsequently raised an issue. Upon seeing the issue, the developer provided a solution (through editing the code and submitting a patch to address the problem). We will provide you with the complete description of the issue raised by the user, as well as the detailed description of the patch generated by the developer to fix the problem. Compared to standard diff format patches, each line of the patch we provide shows the old and new line numbers (in the main part of the patch, the first number at the beginning of each line represents the old line number, and the second number represents the new line number). We believe this will better help you complete the following tasks. You need to carefully review the issue description and patch information and determine whether the correct solution provided in the patch appears in the issue description text, and if so, in what form it is presented. For the "form of presentation," you need to choose from the following options:
(1) Option: Exact Patch. Explanation: The issue description text provided a code-form solution to the problem that is exactly the same or as the correct patch we provided. If there is any semantic discrepancy in between, for instance, if the code snippet provided in the issue to solve the problem can only cover part of our standard patch rather than the entire content, then this option should not be selected. A simple way to help you judge is to compare the information given in the issue description with our provided standard patch. Check which of the edited lines in the latter are covered. If it does not cover all of them, then this option should not be selected.
(2) Option: Complete Steps in NL. Explanation: The issue description text provided a complete description of the solution in natural language, typically explaining how to modify the code step-by-step to fix the problem. This description must be semantically consistent with the correct patch we provided, meaning that one could reasonably be expected to write the correct patch based on this natural language description without needing additional guidance. If there is any semantic discrepancy in between, for instance, if the natural language description provided in the issue to solve the problem can only cover part of our standard patch rather than the entire content, then this option should not be selected. A simple way to help you judge is to compare the information given in the issue description with our provided standard patch. Check which of the edited lines in the latter are covered. If it does not cover all of them, then this option should not be selected.
(3) Option: Some Steps in NL. Explanation: The issue description text provided a partial description of the solution in natural language, but this description is not semantically complete compared to the patch we provided. There might also existing some code snippets that do not provide a complete fix semantics. In other words, one could reasonably be expected to write part of the correct patch based on this natural language description (and code snippet) without needing additional guidance, but not all. This situation is common when the user raising the issue has an incomplete or limited understanding of the problem and provides a partial solution that does not cover all cases but still offers some positive guidance for the developer in writing the correct patch.
(4) Option: No Solution. Explanation: The issue description text did not provide any description of a solution; the user only pointed out the problem without suggesting how to fix it.
(5) Option: Misleading Information. Explanation: The issue description text includes the user's guess on how the problem should be solved, but upon comparison with the correct patch we provided, this guess is found to be completely wrong and entirely off track. Therefore, it should be regarded as misleading information.

Please note that from option (1) to (5), the quality of the user's solution in the issue text decreases progressively. If multiple options are satisfied simultaneously, you should respond with the highest level of option (for example, if Exact Patch, Complete Steps in NL, and Some Steps in NL are all satisfied, your annotation result should be Exact Patch).

Your final report must be written in the following format:
```
## Annotation Level: xxx (choose one from the five options)
## Supporting Reason: xxx (be as concise as possible)
```
"""
        },     
        {
            "role": "user",
            "content":                 
f"""
The issue description is as follows:
```
{problem_statment}
```

The patch content to resolve this issue is as follows:
```
{patch_content}
```
Please return the annotated report to me as required after careful reading and analysis.
"""
        }
    ]
    response, usage = get_llm_response("deepseek/deepseek-r1", messages)
    os.makedirs("./predict_dsr1/")
    with open(f"./predict_dsr1/{instance_id}.txt", "w") as file:
        file.write(response)


def worker(task_queue):
    while True:
        task = task_queue.get()
        if task is None:
            break
        item = task
        predict(item)


def main():
    num_processes = 20
    
    with open("../../swe_bench_verified.json", "r") as file:
        items = json.load(file)
    
    patch_info = {}
    for patch_name in os.listdir("../line_level_gt/delta_diff/"):
        with open(os.path.join("../line_level_gt/delta_diff/", patch_name), "r") as file:
            patch_info[patch_name[:-6]] = file.read().strip().replace("\u22ee", "|").replace("\u2502", "|")
    task_queue = multiprocessing.Queue()
    
    pool = []
    for _ in range(num_processes):
        p = multiprocessing.Process(target=worker, args=(task_queue,))
        p.start()
        pool.append(p)

    tasks = []
    for item in items:
        item["patch_content"] = patch_info[item["instance_id"]]
        # if item["instance_id"] in ['astropy__astropy-13977']:
        tasks.append(item)
    print(len(tasks))

    for task in tasks:
        task_queue.put(task)
    
    for _ in range(num_processes):
        task_queue.put(None)

    for p in pool:
        p.join()



if __name__ == "__main__":
    main()